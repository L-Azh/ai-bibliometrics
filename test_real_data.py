"""
ç”¨çœŸå®æ•°æ®æµ‹è¯•
"""

from cnki_parser import quick_parse
from network_builder import NetworkBuilder
from visualizer import Visualizer

# ========== ä¿®æ”¹è¿™é‡Œï¼šå¡«å…¥ä½ çš„æ–‡ä»¶å ==========
FILE_NAME = "å¤§æ•°æ®å®¡è®¡.enw"  # â† æ”¹æˆçœŸå®çš„ï¼Œå¦‚ "å®¡è®¡ç ”ç©¶.enw"
# =============================================

print(f"ğŸ“‚ æ­£åœ¨åˆ†æ: {FILE_NAME}")
print("=" * 60)

# 1. è§£ææ•°æ®
papers, df, stats = quick_parse(FILE_NAME)

print(f"\nğŸ“Š æ•°æ®æ¦‚è§ˆ:")
print(f"  æ–‡çŒ®æ€»æ•°: {stats['total']} ç¯‡")
print(f"  æ—¶é—´èŒƒå›´: {stats['years'][0] if stats['years'] else 'N/A'} - {stats['years'][-1] if stats['years'] else 'N/A'}")
print(f"  ç‹¬ç«‹ä½œè€…: {stats['authors']} äºº")
print(f"  æ¥æºæœŸåˆŠ: {stats['journals']} ç§")
print(f"  æ¶‰åŠæœºæ„: {stats['institutions']} ä¸ª")

# 2. æ˜¾ç¤ºå‰5ç¯‡æ–‡çŒ®
print(f"\nğŸ“„ å‰5ç¯‡æ–‡çŒ®:")
for i, p in enumerate(papers[:5], 1):
    print(f"\n  {i}. {p.title[:50]}...")
    print(f"     ä½œè€…: {', '.join(p.authors[:3])}")
    print(f"     å¹´ä»½: {p.year} | æœŸåˆŠ: {p.journal[:20]}")

# 3. æ„å»ºç½‘ç»œ
print(f"\nğŸ•¸ï¸ æ„å»ºç½‘ç»œ...")
builder = NetworkBuilder(papers)
coauth = builder.build_coauthorship(top_n=50)
inst = builder.build_institution()
keyword = builder.build_keywords(min_freq=2)

# 4. ç”Ÿæˆå¯è§†åŒ–
print(f"\nğŸ¨ ç”Ÿæˆå›¾è°±...")
output_dir = f"output_{FILE_NAME.replace('.enw', '')}"
viz = Visualizer(output_dir)

viz.plot_coauthorship(coauth)
viz.plot_institution(inst)
viz.plot_keywords(keyword)
viz.plot_trend(papers)
viz.plot_wordcloud(papers)
viz.plot_top_authors(papers, top_n=15)

# 5. ä¿å­˜Excel
excel_path = f"{output_dir}/data.xlsx"
df.to_excel(excel_path, index=False)

print(f"\n" + "=" * 60)
print(f"âœ… åˆ†æå®Œæˆï¼")
print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {output_dir}/")
print(f"ğŸ’¾ Excelæ•°æ®: {excel_path}")